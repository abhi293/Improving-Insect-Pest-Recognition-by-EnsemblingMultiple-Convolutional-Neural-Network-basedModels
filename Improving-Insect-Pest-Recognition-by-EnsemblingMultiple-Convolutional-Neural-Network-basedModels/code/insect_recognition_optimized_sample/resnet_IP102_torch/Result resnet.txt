Number epochs : 7
Learning rate(init) : 0.000045
L2 regularization lambda: 0.010000
Dropout rate: 0.200000

              precision    recall  f1-score   support

           0  0.2500000 0.0303030 0.0540541        66
           1  0.0000000 0.0000000 0.0000000         1
           2  0.0000000 0.0000000 0.0000000         0
           3  0.2500000 0.1333333 0.1739130        15
           4  0.3750000 0.1363636 0.2000000        22
           5  0.1250000 0.0666667 0.0869565        15
           6  0.0000000 0.0000000 0.0000000         0
           7  0.0000000 0.0000000 0.0000000         7
           8  0.3750000 0.1578947 0.2222222        19
           9  0.0000000 0.0000000 0.0000000         6
          10  0.1250000 0.1428571 0.1333333         7
          11  0.0000000 0.0000000 0.0000000         4
          12  0.0000000 0.0000000 0.0000000         5
          13  0.0000000 0.0000000 0.0000000         9
          14  0.0000000 0.0000000 0.0000000         1
          15  0.0000000 0.0000000 0.0000000         8
          16  0.0000000 0.0000000 0.0000000         2
          17  0.1250000 0.5000000 0.2000000         2
          18  0.0000000 0.0000000 0.0000000         1
          19  0.0000000 0.0000000 0.0000000         0
          20  0.0000000 0.0000000 0.0000000         2
          21  0.0000000 0.0000000 0.0000000         3
          22  0.0000000 0.0000000 0.0000000         2
          23  0.0000000 0.0000000 0.0000000         1
          24  0.0000000 0.0000000 0.0000000         3
          25  0.0000000 0.0000000 0.0000000         0
          26  0.2500000 0.0952381 0.1379310        21
          27  0.0000000 0.0000000 0.0000000         0
          28  0.5000000 0.0701754 0.1230769        57
          29  0.0000000 0.0000000 0.0000000         2
          30  0.0000000 0.0000000 0.0000000         2
          31  0.0000000 0.0000000 0.0000000         1
          32  0.0000000 0.0000000 0.0000000         0
          33  0.0000000 0.0000000 0.0000000         0
          34  0.0000000 0.0000000 0.0000000         3
          35  0.0000000 0.0000000 0.0000000        13
          36  0.1250000 0.3333333 0.1818182         3
          37  0.0000000 0.0000000 0.0000000         0
          38  0.1250000 0.5000000 0.2000000         2
          39  0.0000000 0.0000000 0.0000000         0
          40  0.1250000 0.2500000 0.1666667         4
          41  0.0000000 0.0000000 0.0000000         0
          42  0.0000000 0.0000000 0.0000000         0
          43  0.0000000 0.0000000 0.0000000         0
          44  0.0000000 0.0000000 0.0000000        32
          45  0.3750000 0.1500000 0.2142857        20
          46  0.0000000 0.0000000 0.0000000         3
          47  0.0000000 0.0000000 0.0000000         4
          48  0.7500000 0.0895522 0.1600000        67
          49  0.1250000 0.1111111 0.1176471         9
          50  0.0000000 0.0000000 0.0000000         0
          51  0.8750000 0.1750000 0.2916667        40
          52  0.0000000 0.0000000 0.0000000         0
          53  0.0000000 0.0000000 0.0000000         4
          54  0.5000000 0.5714286 0.5333333         7
          55  0.0000000 0.0000000 0.0000000         0
          56  0.0000000 0.0000000 0.0000000         0
          57  0.0000000 0.0000000 0.0000000         2
          58  0.0000000 0.0000000 0.0000000         3
          59  0.1250000 0.0500000 0.0714286        20
          60  0.0000000 0.0000000 0.0000000         1
          61  0.7500000 0.1875000 0.3000000        32
          62  0.0000000 0.0000000 0.0000000         0
          63  0.1250000 0.3333333 0.1818182         3
          64  0.0000000 0.0000000 0.0000000         0
          65  0.0000000 0.0000000 0.0000000        12
          66  0.0000000 0.0000000 0.0000000         1
          67  0.0000000 0.0000000 0.0000000         0
          68  0.3750000 0.0967742 0.1538462        31
          69  0.0000000 0.0000000 0.0000000         4
          70  0.0000000 0.0000000 0.0000000         4
          71  0.1250000 0.1000000 0.1111111        10
          72  0.0000000 0.0000000 0.0000000         0
          73  0.7500000 0.2000000 0.3157895        30
          74  0.3750000 0.0517241 0.0909091        58
          75  0.2500000 0.0952381 0.1379310        21
          76  0.0000000 0.0000000 0.0000000         3
          77  0.0000000 0.0000000 0.0000000         4
          78  0.2500000 0.6666667 0.3636364         3
          79  0.0000000 0.0000000 0.0000000         0
          80  0.0000000 0.0000000 0.0000000         4
          81  0.5000000 0.1538462 0.2352941        26
          82  0.1250000 0.5000000 0.2000000         2
          83  0.1250000 0.2000000 0.1538462         5
          84  0.2500000 0.2857143 0.2666667         7
          85  0.0000000 0.0000000 0.0000000         3
          86  0.0000000 0.0000000 0.0000000         0
          87  0.0000000 0.0000000 0.0000000         0
          88  0.0000000 0.0000000 0.0000000         0
          89  0.0000000 0.0000000 0.0000000         2
          90  0.0000000 0.0000000 0.0000000         0
          91  0.0000000 0.0000000 0.0000000         2
          92  0.0000000 0.0000000 0.0000000         0
          93  0.0000000 0.0000000 0.0000000         0
          94  0.0000000 0.0000000 0.0000000         3
          95  0.1250000 1.0000000 0.2222222         1
          96  0.3750000 0.2307692 0.2857143        13
          97  0.2500000 0.4000000 0.3076923         5
          98  0.0000000 0.0000000 0.0000000         0
          99  0.0000000 0.0000000 0.0000000         0
         100  0.0000000 0.0000000 0.0000000         5
         101  0.0000000 0.0000000 0.0000000         1

    accuracy                      0.1004902       816
   macro avg  0.1004902 0.0790669 0.0646550       816
weighted avg  0.3465074 0.1004902 0.1363254       816
Top 1 : 10.049020
Top 3 : 20.343138
Top 5 : 26.470589
Geometric mean : 0.000000
